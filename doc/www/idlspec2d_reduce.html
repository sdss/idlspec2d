<HTML>
<HEAD><TITLE>Reducing Raw SDSS Specroscopic Data</TITLE></HEAD>

<BODY>

<H1 ALIGN="center">Reducing Raw SDSS Specroscopic Data</H1>

These are the instructions for running the spectroscopic pipeline on
the raw SDSS data.  You must first <A HREF="idlspec2d_install.html">install
the IDL code</A>, which are the three products: idlspec2d, idlutils, specflat.

<HR>

<H2 ALIGN="left">The Directory Structure</H2>

<P>
The directory stucture for spectroscopic data is described by environment
variables as follows:
<DL><DD><PRE>
   $RAWDATA_DIR/<I>mmmmm</I> - The raw image, "sdR-<I>cc-eeeeeeee</I>.fit"
   $SPECLOG_DIR/<I>mmmmm</I> - The plug-map files, "plPlugMapM-<I>pppp-mmmmm-rr</I>.par"
</PRE></DD></DL>
where <I>mmmmm</I> refers to an MJD (such as 51690), <I>cc</I> refers
to a camera name (such as b1 for blue-1), <I>pppp</I> refers to a plate
number (such as 0306), <I>eeeeeeee</I> refers to an exposure number
(such as 00003974), and <I>rr</I> refers to a fiber-mapper re-run number
(such as 01).

<P>
At Princeton, these paths would be set as follows:
<DL><DD><PRE>
   RAWDATA_DIR=/u/dss/rawdata
   SPECLOG_DIR=/u/dss/astrolog
</PRE></DD></DL>

<P>
To re-run a plate through the spectro pipeline, you need all of these files.
Both paths must be set appropriately.

<H2 ALIGN="left">Obtaining the Raw Data</H2>

<P>
The raw images for a particular night ($MJD) can be found at:
<DL><DD><PRE>
   sdssdata.princeton.edu:/u/dss/rawdata/$MJD/sdR*.fit
</PRE></DD></DL>

<P>
The plug-map files for a particular night ($MJD) can be found at:
<DL><DD><PRE>
   sdssdata.princeton.edu:/u/dss/astrolog/$MJD/plPlugMapM*.par
</PRE></DD></DL>
These are also available from the CVS product "speclog", though that
may be out of date by several days or weeks.


<H2 ALIGN="left">Generating Plan Files</H2>

<P>
My convention is to put the reduced data in a directory separate from
the data where the top-level directory is $SPECTRO_DATA.  At Princeton,
this would be set to
<DL><DD><PRE>
   SPECTRO_DATA=/u/dss/spectro
</PRE></DD></DL>
Each plate is put in its own subdirectory, so the reductions of plate 306
would be in "/u/dss/spectro/0306".

<P>
Before running the spectro pipeline, you need to build plan files for
each plate.  Create the output directory $SPECTRO_DATA.  From there,
build the plan files...
<DL><DD><PRE>
   IDL> <A HREF="idlspec2d_doc.html#SPPLAN2D">spplan2d</A>
   IDL> <A HREF="idlspec2d_doc.html#SPPLAN1D">spplan1d</A>
</PRE></DD></DL>
This could take an hour to build plan files for all the data taken to date.
However, you can limit this to particular nights of data by setting
keywords to these procedures (see the full documentation).

<P>
The spplan2d command builds the files "spPlan2d-<I>pppp-mmmmm</I>.par".
There is one such file for each night a plate is observed.

<P>
The spplan1d command builds the files "spPlancomb-<I>pppp-mmmmm</I>.par".
This file merges exposures from multiple nights of observations of the same
plate <B>if</B> those observations were taken without re-plugging the plate.
If the plate was re-plugged between nights, then a given fiber will correspond
to different objects in each night, and those nights' data shouldn't be
combined with "spcombine".

<P>
Note that these plan files are ASCII files (in something called a Yanny
parameter format) which can be hand-edited.  That way, you can exclude
particular exposures from a reduction by commenting-out lines with hash
marks (#).

<H2 ALIGN="left">Running from the IDL Prompt</H2>

<P>
It takes approximately 3.5 hours to run one plate through Spectro-2D on
a 1-GHz Pentium-III, and another 4 hours to run Princeton-1D.

<P>
In each output plate directory, you can run the following three commands
from the IDL prompt:
<DL><DD><PRE>
   IDL> <A HREF="idlspec2d_doc.html#SPREDUCE2D">spreduce2d</A>
   IDL> <A HREF="idlspec2d_doc.html#SPCOMBINE">spcombine</A>
   IDL> <A HREF="idlspec2d_doc.html#SPREDUCE1D">spreduce1d</A>
</PRE></DD></DL>

<P>
The spreduce2d command reduces individual exposures to
"spFrame-<I>cc-eeeeeeee</I>.fits" files.

<P>
The spcombine command combines those exposures into the reduced plate
file, "spPlate-<I>pppp-mmmmm</I>.fits".

<P>
The spreduce1d command finds the redshifts, and generates the file
"spZbest-<I>pppp-mmmmm</I>.fits".

<P>
A number of other supplementary files are also produced.  The history
of the reductions are written to log files named "spDiag*.log", and
some PostScript plots are written to "spDiag*.ps".

<H2 ALIGN="left">Running in the Background</H2>

For example, to reduce plate 306 from the command line,
<DL><DD><PRE>
echo "<A HREF="idlspec2d_doc.html#SPREDUCE2D">spreduce2d</A>, 'spPlan2d-0306-51690.par'" | idl >& /dev/null &
</PRE></DD></DL>

<H2 ALIGN="left">Reducing Data Automatically with the Spectro Robot</H2>

<P>
We use an IDL script BATCH2D for batch processing many plates at once:
<DL><DD><PRE>
  <A HREF="idlspec2d_doc.html#BATCH2D">idlspec2d_doc.html#BATCH2D</A>
</PRE></DD></DL>
which in turn calls DJS_BATCH:
<DL><DD><PRE>
  <A HREF="idlutils_doc.html#DJS_BATCH">idlutils_doc.html#DJS_BATCH</A>
</PRE></DD></DL>
This script will run jobs across local or remote networks using rsh
or ssh protocols.  For a remote machine, the raw data files are shipped
across the network, the plate is reduced, then the reductions are shipped
back.  Presumably, this would work just fine on the Fermi farms.  The plan
files need to be built before running this script.

<P>
There is a Spectro-Robot that automatically fetches data, builds plan files,
and reduces it on a day-by-day basis.  The command "sprobot_start" loads
the cron job.  The raw data is copied to the first disk with space listed
in the SPROBOT_LOCALDISKS environment variable, then a link is built from
$RAWDATA_DIR/$MJD to that directory.  At Princeton, the disk list is
something like:
<DL><DD><PRE>
  SPROBOT_LOCALDISKS='/scr/spectro1/data/rawdata /scr/spectro2/data/rawdata'
</PRE></DD></DL>

Other environment variables that need to be set for the Spectro-Robot:
<DL><DD><PRE>
  SPROBOT_LOCALDISKS -- List of local disks to which to copy the data.
  BATCH2DFILE -- Yanny file with list of machines+protocols for Spectro-2D;
                 default file is "$IDLSPEC2D_DIR/examples/batch2d.par".
  BATCH1DFILE -- Yanny file with list of machines+protocols for Princeton-1D
                 default file is "$IDLSPEC2D_DIR/examples/batch1d.par".
  RAWDATA_DIR -- Root directory for links to raw data directories, which
                 then live in $RAWDATA_DIR/$MJD
  ASTROLOG_DIR -- Root directory for astrolog files, which then live in
                  $ASTROLOG_DIR/$MJD.
  SPECLOG_DIR -- This can be identical to $ASTROLOG_DIR, or set by speclog
                 product
  SPECTRO_DATA -- Root directory for output files, which then live in
                  $SPECTRO_DATA/$PLATE.
  IDL_DIR -- Path set by IDL
  IDLUTILS_DIR -- Path set by idlutils product
  IDLSPEC2D_DIR -- Path set by idlspec2d product
  SPECFLAT_DIR -- Path set by specflat product
</PRE></DD></DL>
If the BATCH2DFILE or BATCH1DFILE variables are not set, then the default
files are used.  If any of the other variables are not set, then
"sprobot_start" will issue an error message and fail to load.  A log file
is written to the file "$RAWDATA_DIR/sprobot.log".

<P>
The Spectro-Robot commands:
<DL><DD><PRE>
  sprobot_start   -- Start the Spectro-Robot.
  sprobot_status  -- See if the Spectro-Robot is running.
  sprobot_stop    -- Stop the Spectro-Robot.
</PRE></DD></DL>

Finally, if one wished to *not* run Princeton-1D, then the line containing
"sprobot1d.sh" would have to be removed from the file "sprobot.sh".

<HR>

<ADDRESS> Maintained by
<A HREF="mailto:schlegel@astro.princeton.edu">David Schlegel</A>
at Princeton University, Dept. of Astrophysics, Peyton Hall, Princeton NJ 08544
</ADDRESS>

</BODY>

</HTML>
